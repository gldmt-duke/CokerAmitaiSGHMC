Stochastic Gradient Hamiltonian Monte Carlo proposes using a subset $\tilde{\mathcal{D}}$ of the entire dataset $\mathcal{D}$ to compute the stochastic gradient
\begin{equation*}
	\Delta\tilde{U}(\theta)=-\frac{|\mathcal{D}|}{|\tilde{\mathcal{D}}|}\sum_{x\in\tilde{\mathcal{D}}}\Delta\log p(x|\theta) - \Delta\log p(\theta)
\end{equation*}
which can then be used in the Hamiltonian Monte Carlo equations in the stead of the gradient $\Delta U(\theta)$.

\begin{equation*}
	\prob{y_i=1|\bm{x}_{i},\bm{\beta}}=\frac{\exp\braces{\bm{x}_i^T\bm{\beta}}}{1+\exp\braces{\bm{x}_i^T\bm{\beta}}}
\end{equation*}

